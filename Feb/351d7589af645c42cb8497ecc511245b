DUBAI: TikTok announced an updated system for account enforcement for a smoother content creation experience on the entertainment platform. The move aims to better act against those who repeatedly violate the policies, helping TikTok to remove harmful accounts more efficiently, while promoting a clearer and more consistent experience for most creators who want to follow policies, the company said in a statement. The updated account enforcement system is currently rolling out globally, and TikTok said it would notify all community members as the new system becomes available to them. The existing account enforcement system leverages different types of restrictions, like temporary bans from posting or commenting, to prevent abuse of product features while teaching people about the policies detailed in TikTok’s community guidelines to reduce future violations. While this approach has been effective in reducing harmful content overall, TikTok heard from creators that it can be confusing to navigate. It can disproportionately impact creators who rarely and unknowingly violate a policy, while potentially being less efficient at deterring those who repeatedly violate them. Repeat violators, according to TikTok, tend to follow a pattern. Analysis has found that almost 90 percent violate using the same feature consistently, and over 75 percent violate the same policy category repeatedly. To better address this, TikTok is updating the account enforcement system to support the creator community and remove repeat offenders from the platform. Under the new system, if someone posts content that violates one of TikTok’s community guidelines, the account will accrue a strike as the content is removed. If an account meets the threshold of strikes within either a product feature (i.e. comments, LIVE) or policy (i.e. bullying and harassment), it will be permanently banned. Those policy thresholds can vary depending on a violation’s potential to cause harm to community members. For example, there may be a stricter threshold for violating TikTok policy against promoting hateful ideologies, than for sharing low-harm spam. TikTok will continue to issue permanent bans on the first strike for severe violations, including promoting or threatening violence, showing or facilitating child sexual abuse material, or showing real-world violence or torture. As an additional safeguard, accounts that accrue a high number of cumulative strikes across policies and features will also be permanently banned. Strikes will expire from an account’s record after 90 days. The company said in its statement that these changes are intended to drive more transparency around TikTok’s enforcement decisions and help the community better understand how to follow the community guidelines. To further support creators, TikTok will roll out new features in the Safety Center provided to creators in-app in the coming weeks. These include an “account status” page where creators can easily view the standing of their account, and a “report records” page where creators can see the status of reports they have made on other content or accounts. These new tools add to the notifications creators already receive if they have violated policies, and support creators’ ability to appeal enforcements and have strikes removed if valid. TikTok will also begin notifying creators if they are on the verge of having their account permanently removed. As a separate step toward improving transparency about moderation practices at the content level, TikTok is beginning to test a new feature in some markets that would provide creators with information about which of their videos have been marked as ineligible for recommendation to the “For You” feed, let them know why, and give them the opportunity to appeal.