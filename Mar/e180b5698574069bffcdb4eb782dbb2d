DUBAI/RIYADH: Silicon Valley startup OpenAI caused a sensation when it released ChatGPT, an artificial intelligence-powered chatbot tool capable of formulating detailed, human-like answers on a seemingly limitless range of topics. In retrospect, that was just the start. Google has since announced its own web tool, Bard, in an apparent bid to compete with the viral success of ChatGPT. Both tools are built on large language models, which are trained on vast troves of data in a way that they can generate impressive responses to user prompts. Conversations with ChatGPT — GPT stands for Generative Pre-Trained Transformer — show that the program is capable of explaining complex scientific concepts, writing plays and poetry, composing university dissertations, and even crafting functional lines of computer code. Such programs can hold a conversation with any human user, no matter their IT experience or background, has written fake scientific reports convincing enough to fool scientists, and has even been used to write a children’s book. Described by some experts as a “tipping point” in artificial intelligence technology, ChatGPT responds to “natural language questions on any topic and gives in-depth answers that read as if they were written by a human,” according to the World Economic Forum.   However, the web tools of Microsoft-backed OpenAI and Google have raised fears about their potential misuse to spread disinformation, orchestrate sophisticated deep fake scams, cheat in school exams, and even destroy writing jobs, rendering authors, journalists, and marketing professionals redundant. How the technology is received, responds and is eventually regulated will be closely watched by several of the Arab Gulf states, many of which have launched their own national strategies for adopting and investing in AI. Saudi Arabia launched its National Strategy for Data and Artificial Intelligence in October 2020, aimed at making the Kingdom a global leader in the field as it seeks to attract $20 billion in foreign and local investments by 2030. The Kingdom also aims to transform its workforce by training and developing a pool of 20,000 AI and data specialists. The UAE has likewise made AI investment a top priority, becoming the first nation in the world to appoint a minister of state for artificial intelligence. Omar Sultan Al-Olama took on the brief in October 2017 to spearhead the UAE’s expanding digital economy. The Middle East is projected to accrue 2 percent of the total global benefits of AI by the end of the decade, equivalent to $320 billion, with AI expected to contribute more than $135.2 billion to the Saudi economy, according to PwC. Founded in late 2015, OpenAI is led by Sam Altman, a 37-year-old entrepreneur and former president of startup incubator Y Combinator. The firm is best known for its automated creation software GPT-3 for text generation and DALL-E for image generation. OpenAI has long counted on financial support from tech industry leaders, including LinkedIn co-founder Reid Hoffman, investor Peter Thiel, and Tesla boss Elon Musk, who served on the start-up’s board until 2018. In January this year, multinational tech corporation Microsoft upped its initial 2019 investment in the firm worth $1 billion to $10 billion, meaning the company is now valued at roughly $29 billion. Google’s core product — online search — is widely thought to be facing its most significant challenge since its launch in 1996. Reports claim the enormous attention being attracted by ChatGPT has spurred Google’s management to declare a “code red” situation for its search business. ChatGPT is being used to obtain answers to questions many people would previously have searched for on Google’ flagship search tool. Last month, Microsoft announced that the next version of its Bing search engine would be powered by OpenAI. Also on the cards is a new version of the Edge web browser with OpenAI chat tech in a window to help users browse and understand web pages. Unfortunately for Google, Bard had an embarrassing debut in early February when a video demo of the chatbot showed it giving the wrong answer to a question about the James Webb space telescope. “ChatGPT is indeed very interesting,” Noaman Sayed, a Dubai-based tech professional and co-founder of the online shopping website DeenSquare, told Arab News. “If you look into the past, every innovation and advancement has had discussions raised in relation to concern, whether it was planes, cars, mobiles, the internet, Google, YouTube, social media and more. “Looking back, we can all say that these have eventually made not only our lives easier, they are also seen as the norm now. I’m very optimistic that with further development and time, ChatGPT will also make our lives easier and shall be the norm.” Not everyone is as optimistic as Sayed, however. Given the rapid pace of technological change now underway, many workers are concerned their professional functions will soon be entirely replaced by machinery, in the same way earlier bouts of automation eliminated farming and manufacturing jobs. Many industry experts argue such job losses will likely be offset by a rise in the number of new skilled roles in designing, building and maintaining AI products, necessitating a shift in the kind of education governments ought to provide to their future workforce. • $119.78bn AI’s estimated global market value in 2022. • $15.7tn What AI is expected to contribute to the global economy by 2030. • 13x AI industry’s projected growth over next 8 years. • 97m Projected number of people working in AI by 2024. Although Sayed accepts AI will alter the way people interact and communicate, he is confident humans will “learn how to adapt with changes over time” in the same way they accepted and adjusted to past technological leaps. In many ways, they already are. “Over the last few years, some of us may have already engaged with some form of AI product (knowingly or unknowingly) during our discussion with call centers, websites chatbots, hospital surgeries, Siri, Alexa, some Google products, certain vehicle manufacturers and more,” he said. Beyond the future job market, chatbots are also creating headaches for educational institutions. Some colleges have reintroduced paper-based tests to stop students from using AI during exams after some students were caught using chatbots to answer test questions. New York City’s education department has banned ChatGPT on its networks because of “concerns about negative impacts on student learning.” A group of Australian universities have also said they would change exam formats to prevent AI cheating. On January 27, the Sciences Po school in Paris, one of the most prestigious universities in France, announced that anyone found to have used the chatbot would face “sanctions which can go as far as expulsion from the establishment or even from higher learning.” Using data harvested from the web, ChatGPT was even able to pass exams at Minnesota University Law School after writing essays on topics ranging from constitutional law to taxation and torts — reportedly earning a C+ grade. Some companies are now marketing programs they claim can catch a text written by AI to help prevent cheating.   Despite the temptation to rely on such programs to answer exam questions, replace existing search engines, or provide unbiased news coverage, Jenna Burrell, director of research at Data & Society, an independent non-profit research organization based in California, said people need to take ChatGPT’s answers with a pinch of salt. “ChatGPT simplifies things and is fun to play with. (It) can be very useful for journalists,” Burrell said during a recent webinar on how the technology might impact the work of media professionals. However, the information it gives “is not up to date…(and) there is a need for fact-checking.” Burrell said AI is not going to be able to replace every professional function, as it cannot fully imitate human innovation, creativity, skepticism, and reasoning. Furthermore, ChatGPT, which is based on “a large-language model,” is not the only emergent form of AI — and not necessarily its most sophisticated. Reinforcement learning, generative adversarial networks, and symbolic AI are all alternative models that are nipping at its heels. “Large-language models are trained by pouring into them billions of words of everyday text, gathered from sources ranging from books to tweets and everything in between. The LLMs draw on all this material to predict words and sentences in certain sequences,” Dan Milmo and Alex Hern, the tech editors of the UK’s Guardian newspaper, said in a recent feature. “LLMs do not understand things in a conventional sense — and they are only as good, or as accurate, as the information with which they are provided. They are essentially machines for matching patterns. Whether the output is ‘true’ is not the point, so long as it matches the pattern.” Asked directly by Arab News whether it ultimately plans to replace human writers, ChatGPT offered a measure of reassurance — appearing to acknowledge its own creative and analytical limitations in a tone that might be construed as modesty. “My abilities are limited to generating text based on patterns and patterns I have seen during my training on text data,” ChatGPT said. “Human writers bring creativity, emotion and personal perspective that I am not able to replicate. Moreover, human writers are able to interpret, analyze and bring their own perspective and insight to a text.”   ChatGPT said it was programmed to “assist” in content creation on social media, blogs, and websites and write business plans, reports, emails and presentations; legal documents such as contracts; medical reports and summaries; and responses to customer inquiries and complaints. Despite its many possible applications, in everything from entertainment to medical diagnosis, and its immense investment potential, with forecasts valuing in the trillions of dollars, the age of AI remains fraught with anxiety. “Trust is key to the safe expansion of the use of AI solutions around the world, Dr. Scott Nowson, PwC Middle East’s artificial intelligence lead, told Arab News at the LEAP technology conference in Riyadh in early February. While there are “some skills and some tasks that are better suited to automation with technology,” he said, the use of AI is “still contingent upon human intelligence and awareness.” Nowson added: “There’s as much optimism as there is pessimism over AI. People believe AI will completely replace us when I really don’t think it will. I think we’re many generations away from when AI becomes greater than human capabilities.” As the nations of the Gulf region pursue their national AI strategies, establishing schools to teach the next generation of tech developers, it is only a matter of time before similar products emerge on the regional market. Sayed, the DeenSquare co-founder, expects governments, businesses, and tech developers across the Gulf region to follow AI-powered tools’ growth and applications with interest. “I’m certain that in their upcoming strategy review meetings, the latest trends will be discussed to see how it can assist in their strategy to their advantage.”